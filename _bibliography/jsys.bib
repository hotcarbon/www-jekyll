@article{2021-09-1-razaSOK,
  type = {Systemization of {{Knowledge}} ({{SoK}})},
  title = {Function-as-a-{{Service}}: {{From An Application Developer}}'s {{Perspective}}},
  author = {Raza, Ali and Matta, Ibrahim and Akhtar, Nabeel and Kalavri, Vasiliki and Isahagian, Vatche},
  year = {2021},
  month = sep,
  journal = {Journal of Systems Research},
  volume = {1},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR31154815},
  url = {https://escholarship.org/uc/item/1wg7h0qf},
  urldate = {2021-09-21},
  abstract = {A survey paper on the state of serverless computing from a developer's perspective.},
  area = {Serverless Systems},
  langid = {english},
  review_url = {https://openreview.net/forum?id=VdWaMgaTKtX}
}

@article{2021-09-2-whittakerSOK,
  type = {Systemization of {{Knowledge}} ({{SoK}})},
  title = {A {{Generalized Multi-Leader State Machine Replication Tutorial}}},
  author = {Whittaker, Michael and Giridharan, Neil and Szekeres, Adriana and Hellerstein, Joseph and Stoica, Ion},
  year = {2021},
  month = sep,
  journal = {Journal of Systems Research},
  volume = {1},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR31154817},
  url = {https://escholarship.org/uc/item/9w79h2jg},
  urldate = {2021-09-21},
  abstract = {Everything you always wanted to know about generalized multi-leader state machine replication protocols but were afraid to ask.},
  area = {Distributed Consensus},
  langid = {english},
  review_url = {https://openreview.net/forum?id=4Xo8nv5DNS}
}

@article{2021-09-3-whittakerSolution,
  type = {Solution},
  title = {Matchmaker {{Paxos}}: {{A Reconfigurable Consensus Protocol}}},
  author = {Whittaker, Michael and Giridharan, Neil and Szekeres, Adriana and Hellerstein, Joseph and Howard, Heidi and Nawab, Faisal and Stoica, Ion},
  year = {2021},
  month = sep,
  journal = {Journal of Systems Research},
  volume = {1},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR31154842},
  url = {https://escholarship.org/uc/item/8wk3343k},
  urldate = {2021-09-21},
  abstract = {Donut Paxos is a reconfigurable consensus protocol that leverages ideas from Vertical Paxos, DPaxos, and Flexible Paxos.},
  area = {Distributed Consensus},
  artifacts_url = {https://github.com/mwhittaker/frankenpaxos/},
  langid = {english},
  review_url = {https://openreview.net/forum?id=bXe1agiq9LN}
}

@article{2021-11-4-jacobTool,
  type = {Tools/{{Benchmark}}},
  title = {Designing {{Replicable Networking Experiments With Triscale}}},
  author = {Jacob, Romain and Zimmerling, Marco and Boano, Carlo Alberto and Vanbever, Laurent and Thiele, Lothar},
  year = {2021},
  month = nov,
  journal = {Journal of Systems Research},
  volume = {1},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR31155408},
  url = {https://escholarship.org/uc/item/63n4s9w2},
  urldate = {2021-11-15},
  abstract = {When designing their performance evaluations, networking researchers often encounter questions such as: How long should a run be? How many runs to perform? How to account for the variability across multiple runs? What statistical methods should be used to analyze the data? Despite their best intentions, researchers often answer these questions differently, thus impairing the replicability of their evaluations and the confidence in their results. In this paper, we propose a concrete methodology for the design and analysis of performance evaluations. Our approach hierarchically partitions the performance evaluation into three timescales, following the principle of separation of concerns. The idea is to understand, for each timescale, the temporal characteristics of variability sources, and then to apply rigorous statistical methods to derive performance results with quantifiable confidence in spite of the inherent variability. We implement this methodology in a software framework called TriScale. For each performance metric, TriScale computes a variability score that estimates, with a given confidence, how similar the results would be if the evaluation were replicated; in other words, TriScale quantifies the replicability of evaluations. We showcase the practicality and usefulness of TriScale on four different case studies demonstrating that TriScale helps to generalize and strengthen published results. Improving the standards of replicability in networking is a complex challenge. This paper is an important contribution to this endeavor; it provides networking researchers with a rational and concrete experimental methodology rooted in sound statistical foundations. The first of its kind.},
  area = {Networking},
  artifacts_url = {https://github.com/romain-jacob/triscale},
  langid = {english},
  review_url = {https://openreview.net/forum?id=c1LNi8CTPy6}
}

@article{2022-03-07-zakiSolution,
  type = {Solution},
  title = {{{ALCC}}: {{Migrating Congestion Control To The Application Layer In Cellular Networks}}},
  shorttitle = {{{ALCC}}},
  author = {Zaki, Yasir and Asim, Rohail and Khan, Muhammad and Iyer, Shiva and Ahmad, Talal and Potsch, Thomas and Subramanian, Lakshmi},
  year = {2022},
  month = mar,
  journal = {Journal of Systems Research},
  volume = {2},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR32156656},
  url = {https://escholarship.org/uc/item/3989w2s4},
  urldate = {2022-03-07},
  abstract = {TCP is known to perform poorly in cellular network environ- ments. Yet, most mobile applications are explicitly built on the conventional TCP stack or implicitly leverage TCP tun- nels to various cellular middleboxes, including performance- enhancing proxies, application-specific edge proxies, VPN proxies and NAT boxes. Despite significant advances in the design of new congestion control (CC) protocols for cellular networks, deploying these protocols without bypassing the underlying TCP tunnels has remained a challenging propo- sition. This paper proposes the design of a new Application Layer Congestion Control (ALCC) framework that allows any new CC protocol to be implemented easily at the application layer, within or above an application-layer protocol that sits atop a legacy TCP stack. It drives it to deliver approximately the same as the native performance. The ALCC socket sits on top of a traditional TCP socket. Still, it can leverage the large congestion windows opened by TCP connections to carefully execute an application-level CC within the window bounds of the underlying TCP connection. This paper demonstrates how ALCC can be applied to three well-known cellular CC pro- tocols: Verus, Copa, and Sprout. For these protocols, ALCC can achieve comparable throughput and delay characteristics (within 3-10\%) as the native protocols at the application layer across different networks and traffic conditions. ALCC al- lows a server-side implementation of these protocols with no client modifications and with zero bytes overhead. The ALCC framework can be easily integrated with off-the-shelf applications such as file transfers and video streaming.},
  area = {Networking},
  artifacts_url = {https://github.com/comnetsAD/ALCC},
  langid = {english},
  review_url = {https://openreview.net/forum?id=moVPhXtxQo7}
}

@article{2022-06-22-seshagiriSoK,
  type = {{{SoK}}},
  ids = {seshagiri2022SOK},
  title = {Identifying {{Mismatches Between Microservice Testbeds}} and {{Industrial Perceptions}} of {{Microservices}}},
  author = {Seshagiri, Vishwanath and Huye, Darby and Liu, Lan and Wildani, Avani and Sambasivan, Raja R.},
  year = {2022},
  month = jun,
  journal = {Journal of Systems Research},
  volume = {2},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR32157839},
  url = {https://escholarship.org/uc/item/5v3489k8},
  urldate = {2022-06-22},
  abstract = {Industrial microservice architectures vary so wildly in their characteristics, such as size or communication method, that comparing systems is difficult and often leads to confusion and misinterpretation. In contrast, the academic testbeds used to conduct microservices research employ a very constrained set of design choices. This lack of systemization in these key design choices when developing microservice architectures has led to uncertainty over how to use experiments from testbeds to inform practical deployments and indeed whether this should be done at all. We conduct semi-structured interviews with industry participants to understand the representativeness of existing testbeds' design choices. Surprising results included the presence of cycles in industry deployments, as well as a lack of clarity about the presence of hierarchies. We then systematize the possible design choices we learned about from the interviews, and identify important mismatches between our interview results and testbeds' designs that will inform future, more representative testbeds.},
  area = {Serverless},
  langid = {english},
  review_url = {https://openreview.net/forum?id=SzgbRfqFRY}
}

@article{2022-07-21-licciardelloSolution,
  type = {Solution},
  ids = {licciardello2022Solution},
  title = {Prepare Your Video for Streaming with {{Segue}}},
  author = {Licciardello, Melissa and Humbel, Lukas and Rohr, Fabian and Gr{\"u}ner, Maximilian and Singla, Ankit},
  year = {2022},
  month = jul,
  journal = {Journal of Systems Research},
  volume = {2},
  number = {1},
  doi = {10.5070/SR32158113},
  url = {https://escholarship.org/uc/item/8m39f25q},
  urldate = {2022-07-21},
  abstract = {We identify new opportunities in video streaming, involving the joint consideration of offline video chunking and on-line rate adaptation. Due to a video's complexity varyingover time, certain parts are more likely to cause performanceimpairments during playback with a particular rate adaptationalgorithm. To address such an issue, we propose Segue ,which carefully uses variable-length video segments, and augment specific segments with additional bitrate tracks. The keynovelty of our approach is in making such decisions basedon the video's time-varying complexity and the expected rateadaptation behavior over time. We propose and implementseveral methods for such adaptation-aware chunking. Ourresults show that Segue substantially reduces rebufferingand quality fluctuations, while maintaining video quality delivered; Segue improves QoE by 9\% on average, and by 22\%in low-bandwidth conditions. Finally, we view our problemframing as a first step in a new thread on algorithmic anddesign innovation in video streaming, and leave the readerwith several interesting open questions.},
  area = {Networking},
  artifacts_url = {https://github.com/melADTR/Segue},
  langid = {english},
  review_url = {https://openreview.net/forum?id=iUU6Qr3eQd6}
}

@article{2022-08-29-sinhaSolution,
  type = {Solution},
  ids = {sinha2022Solution},
  title = {End-to-End Scheduling of Real-Time Task Pipelines on Multiprocessors},
  author = {Sinha, Soham and West, Richard},
  year = {2022},
  month = aug,
  journal = {Journal of Systems Research},
  volume = {2},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR32158647},
  url = {https://escholarship.org/uc/item/2h11n6xj},
  urldate = {2022-08-29},
  abstract = {Task pipelines are common in today's embedded systems, as data moves from source to sink in sensing-processing-actuation task chains. A real-time task pipeline is constructed by connecting a series of periodic tasks with data buffers. In a time-critical system, end-to-end timing and data-transfer properties of a task pipeline must be guaranteed. A guarantee could be mathematically expressed by assigning constraints to the tasks of a pipeline. However, deriving task scheduling parameters to meet end-to-end guarantees is an NP-hard constraint optimization problem. Hence, a traditional constraint solver is not a suitable runtime solution. In this paper, we present a heuristic constraint solver algorithm, CoPi, to derive the execution times and periods of pipelined tasks that meet the end-to-end constraints and schedulability requirements. We consider two upper bound constraints on a task pipeline: end-to-end delay and loss-rate. After satisfying these constraints, CoPi schedules a pipeline as a set of asynchronous and data independent periodic tasks, under the rate-monotonic scheduling algorithm. Simulations show that CoPi has a comparable pipeline acceptance ratio and significantly better runtime than open-source MINLPsolvers. Furthermore, we use CoPi to map multiple task pipelines to a multiprocessor system. We demonstrate that a partitioned multiprocessor scheduling algorithm coupled with CoPi accommodates dynamically appearing pipelines, while attempting to minimize task migrations.},
  area = {Real-time and Cyber-physical Systems},
  artifacts_url = {https://github.com/sohamm17/pipe\textsubscript{s}chedule},
  langid = {english},
  review_url = {https://openreview.net/forum?id=icP8jy6ayy8}
}

@article{2022-09-28-LeznikSoK,
  type = {Sok},
  title = {The {{Great GAN Bake Off}}, {{An Extensive Systematic Evaluation}} of {{Generative Adversarial Network Architectures}} for {{Time Series Synthesis}}},
  author = {Leznik, Mark and Lochner, Arne and Wesner, Stefan and Domaschka, J{\"o}rg},
  year = {2022},
  month = sep,
  journal = {Journal of Systems Research},
  volume = {2},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR32159045},
  url = {https://escholarship.org/uc/item/33h6w78g},
  urldate = {2022-09-28},
  abstract = {There is no standard approach to compare the success ofdifferent neural network architectures utilized for time seriessynthesis. This hinders the evaluation and decision process,as to which architecture should be leveraged for an unknowndata set. We propose a combination of metrics, which empiri-cally evaluate the performance of neural network architecturestrained for time series synthesis. With these measurementswe are able to account for temporal correlations, spatial cor-relations and mode collapse issues within the generated timeseries.We further investigate the interaction of different genera-tor and discriminator architectures between each other. Theconsidered architectures include recurrent neural networks,temporal convolutional networks and transformer-based net-works. So far, the application of transformer-based models islimited for time series synthesis. Hence, we propose a newtransformer-based architecture, which is able to synthesisetime series. We evaluate the proposed architectures and theircombinations in over 500 experiments, amounting to over2500 computing hours. We provide results for four data sets,one univariate and three multivariate. The data sets vary withregard to length, as well as patterns in temporal and spatialcorrelations.We use our metrics to compare the performance of genera-tive adversarial network architectures for time series synthesis.To verify our findings we utilize quantitative and qualitativeevaluations. Our results indicate that temporal convolutionalnetworks currently outperform recurrent neural network andtransformer based approaches with regard to fidelity and flex-ibility of the generated time series data. Temporal convolu-tional network architecture are the most stable architecture fora mode collapse prone data set. The performance of the trans-former models strongly depends on the data set characteristics,it struggled to synthesise data sets with high temporal andspatial correlations. Discriminators with recurrent networkarchitectures suffer from vanishing gradients. We also show,that the performance of the generative adversarial networksdepends more on the discriminator rather than the generator.},
  area = {Systems for ML and ML for Systems},
  langid = {english},
  review_url = {https://openreview.net/forum?id=S6fWW0G9t0t}
}

@article{2022-10-24-stathakopoulouSolution,
  type = {Solution},
  ids = {Sol_Mir-BFT},
  title = {Mir-{{BFT}}: {{Scalable}} and {{Robust BFT}} for {{Decentralized Networks}}},
  shorttitle = {Mir-{{BFT}}},
  author = {Stathakopoulou, Chrysoula and David, Tudor and Pavlovic, Matej and Vukoli{\'c}, Marko},
  year = {2022},
  month = oct,
  journal = {Journal of Systems Research},
  volume = {2},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR32159278},
  url = {https://escholarship.org/uc/item/36g369xq},
  urldate = {2022-10-24},
  abstract = {This paper presents Mir-BFT, a robust Byzantine fault-tolerant (BFT) total order broadcast protocol aimed at maxi-mizing throughput on wide-area networks (WANs), targetingdeployments in decentralized networks, such as permissionedand Proof-of-Stake permissionless blockchain systems.Mir-BFT is the first BFT protocol that allows multiple lead-ers to propose request batches independently (i.e., parallelleaders), while effectively precluding performance degrada-tion due to request duplication by rotating the assignmentof a partitioned request hash space to leaders. As this mech-anism removes the single-leader bandwidth bottleneck andexposes a computation bottleneck related to authenticatingclients even on a WAN, our protocol further boosts through-put using a client signature verification sharding optimization.Our evaluation shows that Mir-BFT outperforms state-of-the-art single-leader protocols and orders more than 60000 signedBitcoin-sized (500-byte) transactions per second on a widelydistributed setup (100 nodes, 1 Gbps WAN) with typical la-tencies of few seconds. Moreover, our evaluation exposesthe impact of duplicate requests on parallel leader protocolswhich Mir-BFT eliminates. We also evaluate Mir-BFT un-der different crash and Byzantine faults, demonstrating itsperformance robustness.Mir-BFT relies on classical BFT protocol constructs, whichsimplifies reasoning about its correctness. Specifically, Mir-BFT is a generalization of the celebrated and scrutinizedPBFT protocol. In a nutshell, Mir-BFT follows PBFT ``safety-wise'', with changes needed to accommodate novel featuresrestricted to PBFT liveness.},
  area = {Distributed Consensus},
  artifacts_url = {https://github.com/hyperledger-labs/mirbft/tree/research},
  langid = {english},
  review_url = {https://openreview.net/forum?id=kCKRUcUGSup}
}

@article{2023-02-01-uferSolution,
  type = {Solution},
  ids = {Sol<sub>K</sub>evoHeap},
  title = {Algorithmic {{Heap Layout Manipulation}} in the {{Linux Kernel}}},
  shorttitle = {{{KevoHeap}}},
  author = {Ufer, Max Jens and Baier, Daniel},
  year = {2023},
  month = feb,
  journal = {Journal of Systems Research},
  volume = {3},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR33160040},
  url = {https://escholarship.org/uc/item/8ss3f7w1},
  urldate = {2023-02-01},
  area = {Systems Security},
  artifacts_url = {https://github.com/fkie-cad/Algorithmic-Heap-Layout-Manipulation-in-the-Linux-Kernel},
  langid = {english},
  review_url = {https://openreview.net/forum?id=UqszJh5h6v}
}

@article{2023-06-06-hellingsProblem,
  type = {Problem},
  ids = {Pblm_Sharded_Tx_Processing},
  title = {Cerberus: {{Minimalistic Multi-shard Byzantine-resilient Transaction Processing}}},
  shorttitle = {Cerberus},
  author = {Hellings, Jelle and Hughes, Daniel P. and Primero, Joshua and Sadoghi, Mohammad},
  year = {2023},
  month = jun,
  journal = {Journal of Systems Research},
  volume = {3},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR33161314},
  url = {https://escholarship.org/uc/item/6h427354},
  urldate = {2023-06-06},
  abstract = {To enable scalable resilient blockchain systems, several powerful general-purpose approaches toward sharding such systems have been demonstrated. Unfortunately, these approaches all come with substantial costs for ordering andexecution of multi-shard transactions.In this work, we ask whether one can achieve significantcost reductions for processing multi-shard transactions by limiting the type of workloads supported. To initiate the study of this problem, we propose CERBERUS, a family of minimalistic primitives for processing single-shard and multi-shard UTXO-like transactions. The first CERBERUS variant we propose is core-CERBERUS (CCERBERUS). CCERBERUS uses strict UTXO-based environmental requirements to enable powerful multi-shard transaction processing with an absolute minimum amount of coordination between shards. In the environment we designed CCERBERUS for, CCERBERUS will operate perfectly with respect to all transactions proposed and approved by well-behaved clients, but does not provide any other guarantees.To illustrate that CCERBERUS -like protocols can also be of use in environments with faulty clients, we also demonstrate two generalizations of CCERBERUS, optimistic-CERBERUS and resilient-CERBERUS, that make different tradeoffs in complexity and costs when dealing with faulty behavior and attacks. Finally, we compare these three protocols and show their potential scalability and performance benefits over state-of-the-art general-purpose systems. These results underline the importance of the study of specialized approaches toward sharding in resilient systems.},
  area = {Distributed Consensus},
  langid = {english},
  review_url = {https://openreview.net/forum?id=s-78X2Y9sm}
}

@article{2023-06-12-hellingsSolution,
  type = {Solution},
  ids = {Sol_Byz_Cluster_Sending},
  title = {Byzantine {{Cluster-Sending}} in {{Expected Constant Cost}} and {{Constant Time}}},
  author = {Hellings, Jelle and Sadoghi, Mohammad},
  year = {2023},
  month = jun,
  journal = {Journal of Systems Research},
  volume = {3},
  number = {1},
  issn = {2770-5501},
  doi = {10.5070/SR33161345},
  url = {https://escholarship.org/uc/item/97s0f1gh},
  urldate = {2023-06-12},
  abstract = {Traditional resilient systems operate on fully-replicated fault-tolerant clusters, which limits their scalability and performance. One way to make the step towards resilient high-performance systems that can deal with huge workloads is by enabling independent fault-tolerant clusters to efficiently communicate and cooperate with each other, as this also enables the usage of high-performance techniques such as sharding. Recently, such inter-cluster communication was formalized as the Byzantine cluster-sending problem. Unfortunately, existing worst-case optimal protocols for cluster-sending all have linear complexity in the size of the clusters involved.In this paper, we propose probabilistic cluster-sending techniques as a solution for the cluster-sending problem with only an expected constant message complexity, this independent of the size of the clusters involved and this even in the presence of highly unreliable communication. Depending on the robustness of the clusters involved, our techniques require only two-to-four message round-trips (without communication failures). Furthermore, our protocols can support worst-case linear communication between clusters. Finally, we have put our techniques to the test in an in-depth experimental evaluation that further underlines the exceptional low expected costs of our techniques in comparison with other protocols. As such, our work provides a strong foundation for the further development of resilient high-performance systems.},
  area = {Distributed Consensus},
  artifacts_url = {https://www.jhellings.nl/projects/csp/},
  langid = {english},
  review_url = {https://openreview.net/forum?id=yuY5n8gMn-s}
}

@article{2023-06-14-hodsdonSolution,
  type = {Solution},
  ids = {Sol_Scaling_Contiguous},
  title = {Mason: {{Scalable}}, {{Contiguous Sequencing}} for {{Building Consistent Services}}},
  shorttitle = {[{{Solution}}] {{Mason}}},
  author = {Hodsdon, Christopher and Stavrinos, Theano and {Katz-Bassett}, Ethan and Lloyd, Wyatt},
  year = {2023},
  month = jun,
  journal = {Journal of Systems Research},
  volume = {3},
  number = {1},
  doi = {10.5070/SR33161354},
  url = {https://escholarship.org/uc/item/5hg1429j},
  urldate = {2023-06-14},
  abstract = {Some recent services use a sequencer to simplify ordering operations on sharded data. The sequencer assigns each operation a multi-sequence number which explicitly orders the operation on each shard it accesses. Existing sequencers have two shortcomings. First, failures can result in some multi-sequence numbers never being assigned, exposing a non-contiguous multi-sequence, which requires complex scaffolding to handle. Second, existing implementations use single-machine sequencers, limiting service throughput to the ordering throughput of one machine.We make two contributions. First, we posit that sequencers should expose our new contiguous multi-sequence abstraction. Contiguity guarantees every sequence number is assigned an operation, simplifying the abstraction. Second, we design and implement MASON , the first system to expose the contiguous multi-sequence abstraction and the first to provide a scalable multi-sequence. MASON is thus an ideal building block for consistent, scalable services. Our evaluation shows MASON unlocks scalable throughput for two strongly-consistent services built on it.},
  area = {Distributed Consensus},
  artifacts_url = {https://github.com/princeton-sns/mason},
  langid = {english},
  review_url = {https://openreview.net/forum?id=hj77eOQNIrx}
}

@article{2023-10-31-hauserTool,
  type = {Tools/{{Benchmark}}},
  ids = {Tool_Extracting_Hardware_Descriptions},
  title = {Automatically {{Extracting Hardware Descriptions}} from {{PDF Technical Documentation}}},
  author = {Hauser, Niklas and Pennekamp, Jan},
  year = {2023},
  journal = {Journal of Systems Research},
  volume = {3},
  number = {1},
  doi = {10.5070/SR33162446},
  url = {https://escholarship.org/uc/item/32z0068j},
  urldate = {2023-10-31},
  abstract = {The ever-increasing variety of microcontrollers aggravatesthe challenge of porting embedded software to new devicesthrough much manual work, whereas code generators can beused only in special cases. Moreover, only little technical documentation for these devices is available in machine-readableformats that could facilitate automating porting efforts. Instead, the bulk of documentation comes as print-orientedPDFs. We hence identify a strong need for a processor toaccess the PDFs and extract their data with a high quality toimprove the code generation for embedded software.In this paper, we design and implement a modular processor for extracting detailed datasets from PDF files containing technical documentation using deterministic table processing for thousands of microcontrollers. Namely, we systematically extract device identifiers, interrupt tables, package and pinouts, pin functions, and register maps. In our evaluation, we compare the documentation from STMicro againstexisting machine-readable sources. Our results show thatour processor matches 96.5 \% of almost 6 million referencedata points, and we further discuss identified issues in bothsources. Hence, our tool yields very accurate data with onlylimited manual effort and can enable and enhance a significant amount of existing and new code generation use cases inthe embedded software domain that are currently limited by alack of machine-readable data sources.},
  area = {Computer Architecture},
  artifacts_url = {https://github.com/salkinium/pdf-data-extraction-jsys-artifact},
  langid = {english},
  review_url = {https://openreview.net/forum?id=yEobnHpBzh}
}

@article{2023-10-31-lambertsSoK,
  type = {{{SoK}}},
  ids = {SoK_Intrusion_Detection},
  title = {Evaluations in {{Industrial Intrusion Detection Research}}},
  author = {Lamberts, Olav and Wolsing, Konrad and Wagner, Eric and Pennekamp, Jan and Bauer, Jan and Wehrle, Klaus and Henze, Martin},
  year = {2023},
  journal = {Journal of Systems Research},
  volume = {3},
  number = {1},
  doi = {10.5070/SR33162445},
  url = {https://escholarship.org/uc/item/43t0z18q},
  urldate = {2023-10-31},
  abstract = {Industrial systems are increasingly threatened by cyberattackswith potentially disastrous consequences. To counter suchattacks, industrial intrusion detection systems strive to timelyuncover even the most sophisticated breaches. Due to its criticality for society, this fast-growing field attracts researchersfrom diverse backgrounds, resulting in 130 new detectionapproaches in 2021 alone. This huge momentum facilitatesthe exploration of diverse promising paths but likewise risksfragmenting the research landscape and burying promisingprogress. Consequently, it needs sound and comprehensibleevaluations to mitigate this risk and catalyze efforts into sustainable scientific progress with real-world applicability. Inthis paper, we therefore systematically analyze the evaluationmethodologies of this field to understand the current stateof industrial intrusion detection research. Our analysis of609 publications shows that the rapid growth of this researchfield has positive and negative consequences. While we observe an increased use of public datasets, publications stillonly evaluate 1.3 datasets on average, and frequently usedbenchmarking metrics are ambiguous. At the same time, theadoption of newly developed benchmarking metrics sees littleadvancement. Finally, our systematic analysis enables us toprovide actionable recommendations for all actors involvedand thus bring the entire research field forward.},
  area = {Real-time and Cyber-physical Systems},
  langid = {english},
  review_url = {https://openreview.net/forum?id=P6tKWm9VpT}
}
